apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ $.ObjectMeta.Name }}
  labels:
    app: {{ $.ObjectMeta.Name }}
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
data:
  core-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
    {{- $count := $.Spec.Hdfs.NameNode.Replicas | int -}}
    {{- if gt $count 1}}
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://nameservice1</value>
      </property>
    {{- else }}
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop-namenode.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:9000/</value>
        <description>NameNode URI</description>
      </property>
    {{- end }}
      <property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop</value>
        <description>指定hadoop运行时产生文件的存储目录</description>
      </property>
      <property>
        <name>ha.zookeeper.quorum</name>
        <value>zookeeper-headless.system.svc.cluster.local:2181</value>
        <description>配置Zookeeper 管理HDFS</description>
      </property>
    </configuration>
  hdfs-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
      </property>

      <property>
        <name>dfs.datanode.use.datanode.hostname</name>
        <value>false</value>
      </property>

      <property>
        <name>dfs.client.use.datanode.hostname</name>
        <value>false</value>
      </property>

      <property>
       <name>dfs.permissions</name>
       <value>false</value>
      </property>

      <property>
        <name>dfs.replication</name>
          <value>3</value>
      </property>

      <property>
        <name>dfs.datanode.data.dir</name>
        <value>file://${hadoop.tmp.dir}/dn</value>
      </property>

      <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://${hadoop.tmp.dir}/nn</value>
      </property>

      <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
      </property>

      <property>
        <name>dfs.namenode.rpc-bind-host</name>
        <value>0.0.0.0</value>
      </property>

      <property>
        <name>dfs.namenode.servicerpc-bind-host</name>
        <value>0.0.0.0</value>
      </property>

    {{- $count := $.Spec.Hdfs.NameNode.Replicas | int -}}
    {{- if gt $count 1}}
      <property>
        <name>dfs.nameservices</name>
        <value>nameservice1</value>
      </property>

      <property>
        <name>dfs.ha.namenodes.nameservice1</name>
        <value>{{- range $i := until (int (.Spec.Hdfs.NameNode.Replicas)) -}}{{ $.ObjectMeta.Name }}-namenode-{{ $i }}{{- if  lt $i (sub $count 1)  -}},{{- end -}}{{- end -}}</value>
      </property>

    {{- range $i := until (int (.Spec.Hdfs.NameNode.Replicas)) }}
       <property>
         <name>dfs.namenode.rpc-address.nameservice1.{{ $.ObjectMeta.Name }}-namenode-{{ $i }}</name>
         <value>hadoop-namenode-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:9000</value>
       </property>
       <property>
         <name>dfs.namenode.http-address.nameservice1.{{ $.ObjectMeta.Name }}-namenode-{{ $i }}</name>
         <value>hadoop-namenode-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:9870</value>
       </property>
     {{- end }}

       <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://hadoop-journalnode.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8485/nameservice1</value>
        <description>指定NameNode的元数据在JournalNode上的存放位置</description>
       </property>

       <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>${hadoop.tmp.dir}/jn</value>
        <description>指定JournalNode在本地磁盘存放数据的位置</description>
       </property>

       <property>
         <name>dfs.ha.automatic-failover.enabled</name>
         <value>true</value>
         <description>开启NameNode失败自动切换</description>
       </property>

       <property>
        <name>dfs.client.failover.proxy.provider.nameservice1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        <description>配置失败自动切换实现方式</description>
       </property>

      <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
        <description>配置隔离机制，即同一时刻只能有一台服务器对外响应</description>
      </property>

      <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>~/.ssh/id_rsa</value>
        <description> 配置隔离机制，即同一时刻只能有一台服务器对外响应</description>
      </property>
    {{- end}}
    </configuration>

  mapred-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

    <configuration>
      <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
      </property>

      <property>
        <name>mapreduce.jobhistory.address</name>
        <value>hadoop-historyserver.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:10020</value>
      </property>
      <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>hadoop-historyserver.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:19888</value>
      </property>
    </configuration>

  workers: |
    {{- $count := $.Spec.Hdfs.DataNode.Replicas | int -}}
    {{- range $i, $e := until $count }}
    {{ $.ObjectMeta.Name }}-datanode-{{ $i }}.hadoop-datanode.{{ $.ObjectMeta.Namespace }}.svc.cluster.local
    {{- end }}

  yarn-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

    <configuration>
      <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>{{ $.ObjectMeta.Name }}-resourcemanager-0</value>
      </property>

      <property>
        <name>yarn.resourcemanager.bind-host</name>
        <value>0.0.0.0</value>
      </property>
      <property>
        <name>yarn.nodemanager.bind-host</name>
        <value>0.0.0.0</value>
      </property>
      <property>
        <name>yarn.timeline-service.bind-host</name>
        <value>0.0.0.0</value>
      </property>

      <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
      </property>

      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>

      <property>
        <name>yarn.resourcemanager.recovery.enabled</name>
        <value>true</value>
        <description>启用自动恢复</description>
      </property>

      <property>
        <name>yarn.nodemanager.localizer.address</name>
        <value>hadoop-nodemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8040</value>
        <description>Address where the localizer IPC is.</description>
      </property>

      <property>
        <name>yarn.nodemanager.webapp.address</name>
        <value>hadoop-nodemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8042</value>
        <description>NodeManager Webapp address</description>
      </property>

      <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
      </property>

      <property>
        <description>List of directories to store localized files in.</description>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
      </property>

      <property>
        <description>Where to store container logs.</description>
        <name>yarn.nodemanager.log-dirs</name>
        <value>/var/log/hadoop-yarn/containers</value>
      </property>

      <property>
        <description>Where to aggregate logs to.</description>
        <name>yarn.nodemanager.remote-app-log-dir</name>
        <value>/var/log/hadoop-yarn/apps</value>
      </property>

    {{- $count := $.Spec.ResourceManager.Replicas | int -}}
    {{- if gt $count 1}}
      <property>
        <name>yarn.resourcemanager.ha.enabled</name>
        <value>true</value>
        <description>启用ResourceManager HA</description>
      </property>

      <property>
        <name>yarn.resourcemanager.cluster-id</name>
        <value>cluster-yarn</value>
        <description>声明三台resourcemanager的地址</description>
      </property>
      <property>
        <name>yarn.resourcemanager.ha.rm-ids</name>
        <value>{{- range $i := until (int ($count)) -}}rm-{{ $i }}{{- if  lt $i (sub $count 1)  -}},{{- end -}}{{- end -}}</value>
        <description>指定resourcemanager的逻辑列表</description>
      </property>

    {{- range $i := until (int ($count)) }}
      <property>
        <name>yarn.resourcemanager.hostname.rm-{{ $i }}</name>
        <value>hadoop-resourcemanager-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local</value>
      </property>
      <property>
        <name>yarn.resourcemanager.scheduler.address.rm-{{ $i }}</name>
        <value>hadoop-resourcemanager-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8030</value>
      </property>
      <property>
        <name>yarn.resourcemanager.resource-tracker.address.rm-{{ $i }}</name>
        <value>hadoop-resourcemanager-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8031</value>
      </property>
      <property>
        <name>yarn.resourcemanager.address.rm-{{ $i }}</name>
        <value>hadoop-resourcemanager-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8032</value>
      </property>
      <property>
        <name>yarn.resourcemanager.webapp.address.rm-{{ $i }}</name>
        <value>hadoop-resourcemanager-{{ $i }}.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8088</value>
      </property>
    {{- end }}
    {{- else }}
      <property>
       <name>yarn.resourcemanager.scheduler.address</name>
       <value>hadoop-resourcemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8030</value>
       <description>RM对AM暴露的地址，AM通过地址想RM申请资源，释放资源等</description>
      </property>
      <property>
       <name>yarn.resourcemanager.resource-tracker.address</name>
       <value>hadoop-resourcemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8031</value>
       <description>RM对NM暴露地址，NM通过该地址向RM汇报心跳，领取任务等</description>
      </property>
      <property>
       <name>yarn.resourcemanager.address</name>
       <value>hadoop-resourcemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8032</value>
       <description>RM对客户端暴露的地址，客户端通过该地址向RM提交应用程序等</description>
      </property>
      <property>
       <name>yarn.resourcemanager.webapp.address</name>
       <value>hadoop-resourcemanager.{{ $.ObjectMeta.Namespace }}.svc.cluster.local:8088</value>
       <description>RM web端地址</description>
      </property>
    {{- end}}

      <property>
        <name>yarn.resourcemanager.zk.state-store.address</name>
        <value>zookeeper-headless.system.svc.cluster.local:2181</value>
        <description>配置Zookeeper地址</description>
      </property>
      <property>
        <name>yarn.resourcemanager.zk-address</name>
        <value>zookeeper-headless.system.svc.cluster.local:2181</value>
      </property>
      <property>
        <name>yarn.resourcemanager.store.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
        <description>指定resourcemanager的状态信息存储在zookeeper集群，默认是存放在FileSystem里面</description>
      </property>

      <property>
        <name>yarn.application.classpath</name>
        <value>
          /usr/local/hadoop/etc/hadoop,
          /usr/local/hadoop/share/hadoop/common/*,
          /usr/local/hadoop/share/hadoop/common/lib/*,
          /usr/local/hadoop/share/hadoop/hdfs/*,
          /usr/local/hadoop/share/hadoop/hdfs/lib/*,
          /usr/local/hadoop/share/hadoop/mapreduce/*,
          /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
          /usr/local/hadoop/share/hadoop/yarn/*,
          /usr/local/hadoop/share/hadoop/yarn/lib/*
        </value>
      </property>
    </configuration>

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-datanode
  labels:
    app: {{ $.ObjectMeta.Name }}-datanode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-datanode
    component: {{ $.ObjectMeta.Name }}-datanode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-datanode
  replicas: {{ $.Spec.Hdfs.DataNode.Replicas }}
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-datanode
      release: {{ $.ObjectMeta.Name }}-datanode
      component: {{ $.ObjectMeta.Name }}-datanode
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-datanode
        release: {{ $.ObjectMeta.Name }}-datanode
        component: {{ $.ObjectMeta.Name }}-datanode
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      nodeSelector:
        app: datanode
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: {{ $.ObjectMeta.Name }}-datanode
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-datanode
          image: {{ $.Spec.Container.Image }}
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          args:
            - "--DataNode"
{{ parseResources $.Spec.Hdfs.DataNode.Resources | indent 10 }}
          readinessProbe:
            httpGet:
              path: /
              port: 9864
            initialDelaySeconds: 5
            timeoutSeconds: 2
          livenessProbe:
            httpGet:
              path: /
              port: 9864
            initialDelaySeconds: 10
            timeoutSeconds: 2
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: dfs
              mountPath: /usr/local/hadoop/dn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: dfs
          hostPath:
            # Ensure the file DirectoryOrCreate is created.
            path: /home/data/dn
            type: DirectoryOrCreate


---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-datanode
  labels:
    app: hadoop
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}
    component: hdfs-dn
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: hadoop
      release: {{ $.ObjectMeta.Name }}
      component: hdfs-dn
  minAvailable: {{ $.Spec.Hdfs.DataNode.Replicas }}

---
apiVersion: v1
kind: Service
metadata:
  name: hadoop-datanode
  labels:
    app: {{ $.ObjectMeta.Name }}-datanode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-datanode
    component: {{ $.ObjectMeta.Name }}-datanode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  ports:
    - name: dfs
      port: 9000
      protocol: TCP
    - name: webhdfs
      port: 9864
  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-datanode
    release: {{ $.ObjectMeta.Name }}-datanode
    component: {{ $.ObjectMeta.Name }}-datanode

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-namenode
  labels:
    app: {{ $.ObjectMeta.Name }}-namenode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-namenode
    component: {{ $.ObjectMeta.Name }}-namenode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-namenode
  replicas: {{ $.Spec.Hdfs.NameNode.Replicas }}
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-namenode
      release: {{ $.ObjectMeta.Name }}-namenode
      component: {{ $.ObjectMeta.Name }}-namenode
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-namenode
        release: {{ $.ObjectMeta.Name }}-namenode
        component: {{ $.ObjectMeta.Name }}-namenode
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      nodeSelector:
        app: namenode
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: namenode
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-namenode
          image: "{{ $.Spec.Container.Image }}"
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          ports:
            - containerPort: 9870
              name: webhdfs
          args:
            - "--NameNode"
            - "--NameNodeDir=$(HDFS_NAME_NODE_DIR)"
          securityContext:
            privileged: true
          env:
            - name: HDFS_NAME_NODE_DIR
              value: "/usr/local/hadoop/nn"
{{ parseResources $.Spec.Hdfs.NameNode.Resources | indent 10 }}
          readinessProbe:
            httpGet:
              path: /
              port: 9870
            initialDelaySeconds: 5
            timeoutSeconds: 2
          livenessProbe:
            httpGet:
              path: /
              port: 9870
            initialDelaySeconds: 10
            timeoutSeconds: 2
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: dfs
              mountPath: /usr/local/hadoop/nn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: dfs
          hostPath:
            # Ensure the file DirectoryOrCreate is created.
            path: /home/data/nn
            type: DirectoryOrCreate

---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-namenode
  labels:
    app: {{ $.ObjectMeta.Name }}-namenode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}
    component: {{ $.ObjectMeta.Name }}-namenode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-namenode
      release: {{ $.ObjectMeta.Name }}-namenode
      component: {{ $.ObjectMeta.Name }}-namenode
  maxUnavailable: 3


{{- $count := $.Spec.Hdfs.NameNode.Replicas | int -}}
{{- range $i := until (int ($count)) }}
---
apiVersion: v1
kind: Service
metadata:
  {{- if gt $count 1 }}
  name: hadoop-namenode-{{ $i }}
  {{- else }}
  name: hadoop-namenode
  {{- end }}
  labels:
    app: {{ $.ObjectMeta.Name }}-namenode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-namenode
    component: {{ $.ObjectMeta.Name }}-namenode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  type: NodePort
  ports:
    - name: dfs
      port: 9000
      protocol: TCP
    - name: webhdfs
      port: 9870
#  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-namenode
    release: {{ $.ObjectMeta.Name }}-namenode
    component: {{ $.ObjectMeta.Name }}-namenode
{{- end }}

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-resourcemanager
  labels:
    app: {{ $.ObjectMeta.Name }}-resourcemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-resourcemanager
    component: {{ $.ObjectMeta.Name }}-resourcemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-resourcemanager
  replicas: 1
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-resourcemanager
      release: {{ $.ObjectMeta.Name }}-resourcemanager
      component: {{ $.ObjectMeta.Name }}-resourcemanager
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-resourcemanager
        release: {{ $.ObjectMeta.Name }}-resourcemanager
        component: {{ $.ObjectMeta.Name }}-resourcemanager
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      nodeSelector:
        app: namenode
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: namenode
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-resourcemanager
          image: "{{ $.Spec.Container.Image }}"
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          ports:
            - containerPort: 8088
              name: web
            - containerPort: 8031
              name: tracker
            - containerPort: 8032
              name: rm-client
            - containerPort: 8034
              name: scheduler
          args:
            - "--ResourceManager"
{{ parseResources $.Spec.ResourceManager.Resources | indent 10 }}
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: nn
              mountPath: /usr/local/hadoop/nn
            - name: dn
              mountPath: /usr/local/hadoop/dn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: nn
          hostPath:
            path: /home/data/nn
            type: DirectoryOrCreate
        - name: dn
          hostPath:
            path: /home/data/dn
            type: DirectoryOrCreate


---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-resourcemanager
  labels:
    app: {{ $.ObjectMeta.Name }}-resourcemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-resourcemanager
    component: {{ $.ObjectMeta.Name }}-resourcemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-resourcemanager
      release: {{ $.ObjectMeta.Name }}-resourcemanager
      component: {{ $.ObjectMeta.Name }}-resourcemanager
  minAvailable: 1


{{- $count := $.Spec.ResourceManager.Replicas | int -}}
{{- range $i := until (int ($count)) }}
---
apiVersion: v1
kind: Service
metadata:
  {{- if gt $count 1 }}
  name: hadoop-resourcemanager-{{ $i }}
  {{- else }}
  name: hadoop-resourcemanager
  {{- end }}
  labels:
    app: {{ $.ObjectMeta.Name }}-resourcemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-resourcemanager
    component: {{ $.ObjectMeta.Name }}-resourcemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  type: NodePort
  ports:
    - port: 8088
      name: web
    - port: 8031
      name: tracker
    - port: 8032
      name: rm-client
    - port: 8030
      name: scheduler
#  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-resourcemanager
    release: {{ $.ObjectMeta.Name }}-resourcemanager
    component: {{ $.ObjectMeta.Name }}-resourcemanager
{{- end }}



---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-nodemanager
  labels:
    app: {{ $.ObjectMeta.Name }}-nodemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-nodemanager
    component: {{ $.ObjectMeta.Name }}-nodemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-nodemanager
  replicas: {{ $.Spec.NodeManager.Replicas }}
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-nodemanager
      release: {{ $.ObjectMeta.Name }}-nodemanager
      component: {{ $.ObjectMeta.Name }}-nodemanager
  {{- if $.Spec.NodeManager.ParallelCreate }}
  podManagementPolicy: Parallel
  {{- end }}
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-nodemanager
        release: {{ $.ObjectMeta.Name }}-nodemanager
        component: {{ $.ObjectMeta.Name }}-nodemanager
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      nodeSelector:
        app: datanode
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: datanode
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-nodemanager
          image: "{{ $.Spec.Container.Image }}"
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          ports:
            - containerPort: 8040
              name: localizer
            - containerPort: 8042
              name: webapp
          args:
            - "--NodeManager"
          securityContext:
            privileged: true
{{ parseResources $.Spec.NodeManager.Resources | indent 10 }}
          readinessProbe:
            httpGet:
              path: /node
              port: 8042
            initialDelaySeconds: 10
            timeoutSeconds: 2
          livenessProbe:
            httpGet:
              path: /node
              port: 8042
            initialDelaySeconds: 10
            timeoutSeconds: 2
          env:
            - name: MY_CPU_LIMIT
              valueFrom:
                resourceFieldRef:
                  containerName: {{ $.ObjectMeta.Name }}-nodemanager
                  resource: limits.cpu
                  divisor: 1
            - name: MY_MEM_LIMIT
              valueFrom:
                resourceFieldRef:
                  containerName: {{ $.ObjectMeta.Name }}-nodemanager
                  resource: limits.memory
                  divisor: 1M
            - name: HDFS_NAME_NODE_DIR
              value: "/usr/local/hadoop/nn"
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: nn
              mountPath: /usr/local/hadoop/nn
            - name: dn
              mountPath: /usr/local/hadoop/dn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: nn
          hostPath:
            path: /home/data/nn
            type: DirectoryOrCreate
        - name: dn
          hostPath:
            path: /home/data/dn
            type: DirectoryOrCreate



---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-nodemanager
  labels:
    app: {{ $.ObjectMeta.Name }}-nodemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-nodemanager
    component: {{ $.ObjectMeta.Name }}-nodemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-nodemanager
      release: {{ $.ObjectMeta.Name }}-nodemanager
      component: {{ $.ObjectMeta.Name }}-nodemanager
  minAvailable: {{ $.Spec.NodeManager.Replicas }}

---
apiVersion: v1
kind: Service
metadata:
  name: hadoop-nodemanager
  labels:
    app: {{ $.ObjectMeta.Name }}-nodemanager
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}
    component: {{ $.ObjectMeta.Name }}-nodemanager
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  ports:
    - port: 8040
      name: localizer
    - port: 8042
      name: webapp
  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-nodemanager
    release: {{ $.ObjectMeta.Name }}-nodemanager
    component: {{ $.ObjectMeta.Name }}-nodemanager



---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-historyserver
  labels:
    app: {{ $.ObjectMeta.Name }}-historyserver
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-historyserver
    component: {{ $.ObjectMeta.Name }}-historyserver
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-historyserver
  replicas: 1
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-historyserver
      release: {{ $.ObjectMeta.Name }}-historyserver
      component: {{ $.ObjectMeta.Name }}-historyserver
  {{- if $.Spec.NodeManager.ParallelCreate }}
  podManagementPolicy: Parallel
  {{- end }}
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-historyserver
        release: {{ $.ObjectMeta.Name }}-historyserver
        component: {{ $.ObjectMeta.Name }}-historyserver
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: {{ $.ObjectMeta.Name }}-historyserver
                  release: {{ $.ObjectMeta.Name }}-historyserver
                  component: {{ $.ObjectMeta.Name }}-historyserver
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-historyserver
          image: "{{ $.Spec.Container.Image }}"
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          ports:
            - containerPort: 10020
              name: jobhistory
            - containerPort: 19888
              name: web
          args:
            - "--HistoryServer"
          securityContext:
            privileged: true
{{ parseResources $.Spec.NodeManager.Resources | indent 10 }}
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: nn
              mountPath: /usr/local/hadoop/nn
            - name: dn
              mountPath: /usr/local/hadoop/dn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: nn
          hostPath:
            path: /home/data/nn
            type: DirectoryOrCreate
        - name: dn
          hostPath:
            path: /home/data/dn
            type: DirectoryOrCreate


---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-historyserver
  labels:
    app: {{ $.ObjectMeta.Name }}-historyserver
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-historyserver
    component: {{ $.ObjectMeta.Name }}-historyserver
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-historyserver
      release: {{ $.ObjectMeta.Name }}-historyserver
      component: {{ $.ObjectMeta.Name }}-historyserver
  minAvailable: 1

---
apiVersion: v1
kind: Service
metadata:
  name: hadoop-historyserver
  labels:
    app: {{ $.ObjectMeta.Name }}-historyserver
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-historyserver
    component: {{ $.ObjectMeta.Name }}-historyserver
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  ports:
    - port: 10020
      name: jobhistory
    - port: 19888
      name: web
  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-historyserver
    release: {{ $.ObjectMeta.Name }}-historyserver
    component: {{ $.ObjectMeta.Name }}-historyserver

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $.ObjectMeta.Name }}-journalnode
  labels:
    app: {{ $.ObjectMeta.Name }}-journalnode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-journalnode
    component: {{ $.ObjectMeta.Name }}-journalnode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
  annotations:
    operator.dameng.com/title: {{ $.Spec.Title | hexenc | quote }}
spec:
  serviceName: {{ $.ObjectMeta.Name }}-journalnode
  replicas: {{ $.Spec.Hdfs.JournalNode.Replicas }}
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-journalnode
      release: {{ $.ObjectMeta.Name }}-journalnode
      component: {{ $.ObjectMeta.Name }}-journalnode
  template:
    metadata:
      labels:
        app: {{ $.ObjectMeta.Name }}-journalnode
        release: {{ $.ObjectMeta.Name }}-journalnode
        component: {{ $.ObjectMeta.Name }}-journalnode
        operator.dameng.com/id: {{ $.Spec.ID | quote }}
        sidecar.istio.io/inject: "false"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: {{ $.ObjectMeta.Name }}-journalnode
                  release: {{ $.ObjectMeta.Name }}-journalnode
                  component: {{ $.ObjectMeta.Name }}-journalnode
      terminationGracePeriodSeconds: 0
      containers:
        - name: {{ $.ObjectMeta.Name }}-journalnode
          image: "{{ $.Spec.Container.Image }}"
          imagePullPolicy: {{ $.Spec.Container.PullPolicy | quote }}
          ports:
            - containerPort: 8485
              name: journalnode
          args:
            - "--JournalNode"
          securityContext:
            privileged: true
{{ parseResources $.Spec.Hdfs.JournalNode.Resources | indent 10 }}
          volumeMounts:
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/mapred-site.xml
              subPath: mapred-site.xml
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/workers
              subPath: workers
            - name: hadoop-config
              mountPath: /usr/local/hadoop/etc/hadoop/yarn-site.xml
              subPath: yarn-site.xml
            - name: jn
              mountPath: /usr/local/hadoop/jn
      volumes:
        - name: hadoop-config
          configMap:
            name: {{ $.ObjectMeta.Name }}
        - name: jn
          hostPath:
            path: /home/data/jn
            type: DirectoryOrCreate

---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: {{ $.ObjectMeta.Name }}-journalnode
  labels:
    app: {{ $.ObjectMeta.Name }}-journalnode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-journalnode
    component: {{ $.ObjectMeta.Name }}-journalnode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  selector:
    matchLabels:
      app: {{ $.ObjectMeta.Name }}-journalnode
      release: {{ $.ObjectMeta.Name }}-journalnode
      component: {{ $.ObjectMeta.Name }}-journalnode
  minAvailable: 3

---
apiVersion: v1
kind: Service
metadata:
  name: hadoop-journalnode
  labels:
    app: {{ $.ObjectMeta.Name }}-journalnode
    chart: hadoop-1.1.4
    release: {{ $.ObjectMeta.Name }}-journalnode
    component: {{ $.ObjectMeta.Name }}-journalnode
    operator.dameng.com/id: {{ $.Spec.ID | quote }}
spec:
  ports:
    - port: 8485
      name: journalnode
  clusterIP: None
  selector:
    app: {{ $.ObjectMeta.Name }}-journalnode
    release: {{ $.ObjectMeta.Name }}-journalnode
    component: {{ $.ObjectMeta.Name }}-journalnode
